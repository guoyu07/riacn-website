<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>第 10 章相关源代码 &mdash; Redis 实战</title>
    
    <link rel="stylesheet" href="../_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Redis 实战" href="../index.html" />
    <link rel="next" title="第 11 章相关源代码" href="chapter11.html" />
    <link rel="prev" title="第 9 章相关源代码" href="chapter9.html" /> 

<!--[if lte IE 6]>
<link rel="stylesheet" href="../_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->


  </head>
  <body>


    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="chapter11.html" title="第 11 章相关源代码"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="chapter9.html" title="第 9 章相关源代码"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Redis 实战</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="id1">
<h1>第 10 章相关源代码<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="highlight-python"><div class="highlight"><pre># coding: utf-8

import binascii
from collections import defaultdict
from datetime import date
from decimal import Decimal
import functools
import json
from Queue import Empty, Queue
import threading
import time
import unittest
import uuid

import redis

CONFIGS = {}
CHECKED = {}

def get_config(conn, type, component, wait=1):
    key = &#39;config:%s:%s&#39;%(type, component)

    if CHECKED.get(key) &lt; time.time() - wait:           #A
        CHECKED[key] = time.time()                      #B
        config = json.loads(conn.get(key) or &#39;{}&#39;)      #C
        config = dict((str(k), config[k]) for k in config)
        old_config = CONFIGS.get(key)                   #D

        if config != old_config:                        #E
            CONFIGS[key] = config                       #F

    return CONFIGS.get(key)

REDIS_CONNECTIONS = {}
config_connection = None

def redis_connection(component, wait=1):                        #A
    key = &#39;config:redis:&#39; + component                           #B
    def wrapper(function):                                      #C
        @functools.wraps(function)                              #D
        def call(*args, **kwargs):                              #E
            old_config = CONFIGS.get(key, object())             #F
            _config = get_config(                               #G
                config_connection, &#39;redis&#39;, component, wait)    #G

            config = {}
            for k, v in _config.iteritems():                    #L
                config[k.encode(&#39;utf-8&#39;)] = v                   #L

            if config != old_config:                            #H
                REDIS_CONNECTIONS[key] = redis.Redis(**config)  #H

            return function(                                    #I
                REDIS_CONNECTIONS.get(key), *args, **kwargs)    #I
        return call                                             #J
    return wrapper                                              #K

def index_document(conn, docid, words, scores):
    pipeline = conn.pipeline(True)
    for word in words:                                                  #I
        pipeline.sadd(&#39;idx:&#39; + word, docid)                             #I
    pipeline.hmset(&#39;kb:doc:%s&#39;%docid, scores)
    return len(pipeline.execute())                                      #J

def parse_and_search(conn, query, ttl):
    id = str(uuid.uuid4())
    conn.sinterstore(&#39;idx:&#39; + id,
        [&#39;idx:&#39;+key for key in query])
    conn.expire(&#39;idx:&#39; + id, ttl)
    return id

def search_and_sort(conn, query, id=None, ttl=300, sort=&quot;-updated&quot;, #A
                    start=0, num=20):                               #A
    desc = sort.startswith(&#39;-&#39;)                                     #B
    sort = sort.lstrip(&#39;-&#39;)                                         #B
    by = &quot;kb:doc:*-&gt;&quot; + sort                                        #B
    alpha = sort not in (&#39;updated&#39;, &#39;id&#39;, &#39;created&#39;)                #I

    if id and not conn.expire(id, ttl):     #C
        id = None                           #C

    if not id:                                      #D
        id = parse_and_search(conn, query, ttl=ttl) #D

    pipeline = conn.pipeline(True)
    pipeline.scard(&#39;idx:&#39; + id)                                     #E
    pipeline.sort(&#39;idx:&#39; + id, by=by, alpha=alpha,                  #F
        desc=desc, start=start, num=num)                            #F
    results = pipeline.execute()

    return results[0], results[1], id                               #G

def zintersect(conn, keys, ttl):
    id = str(uuid.uuid4())
    conn.zinterstore(&#39;idx:&#39; + id,
        dict((&#39;idx:&#39;+k, v) for k,v in keys.iteritems()))
    conn.expire(&#39;idx:&#39; + id, ttl)
    return id

def search_and_zsort(conn, query, id=None, ttl=300, update=1, vote=0,   #A
                    start=0, num=20, desc=True):                        #A

    if id and not conn.expire(id, ttl):     #B
        id = None                           #B

    if not id:                                      #C
        id = parse_and_search(conn, query, ttl=ttl) #C

        scored_search = {                           #D
            id: 0,                                  #D
            &#39;sort:update&#39;: update,                  #D
            &#39;sort:votes&#39;: vote                      #D
        }
        id = zintersect(conn, scored_search, ttl)   #E

    pipeline = conn.pipeline(True)
    pipeline.zcard(&#39;idx:&#39; + id)                                     #F
    if desc:                                                        #G
        pipeline.zrevrange(&#39;idx:&#39; + id, start, start + num - 1)     #G
    else:                                                           #G
        pipeline.zrange(&#39;idx:&#39; + id, start, start + num - 1)        #G
    results = pipeline.execute()

    return results[0], results[1], id                               #H

def execute_later(conn, queue, name, args):
    t = threading.Thread(target=globals()[name], args=tuple(args))
    t.setDaemon(1)
    t.start()

HOME_TIMELINE_SIZE = 1000
POSTS_PER_PASS = 1000

def shard_key(base, key, total_elements, shard_size):   #A
    if isinstance(key, (int, long)) or key.isdigit():   #B
        shard_id = int(str(key), 10) // shard_size      #C
    else:
        shards = 2 * total_elements // shard_size       #D
        shard_id = binascii.crc32(key) % shards         #E
    return &quot;%s:%s&quot;%(base, shard_id)                     #F

def shard_sadd(conn, base, member, total_elements, shard_size):
    shard = shard_key(base,
        &#39;x&#39;+str(member), total_elements, shard_size)            #A
    return conn.sadd(shard, member)                             #B

SHARD_SIZE = 512
EXPECTED = defaultdict(lambda: 1000000)


# 代码清单 10-1
# &lt;start id=&quot;get-connection&quot;/&gt;
def get_redis_connection(component, wait=1):
    key = &#39;config:redis:&#39; + component
    # 尝试获取旧的配置。
    old_config = CONFIGS.get(key, object())           
    # 尝试获取新的配置。
    config = get_config(                                
        config_connection, &#39;redis&#39;, component, wait)    

    # 如果新旧配置不相同，那么创建一个新的连接。
    if config != old_config:                            
        REDIS_CONNECTIONS[key] = redis.Redis(**config)  

    # 返回用户指定的连接对象。
    return REDIS_CONNECTIONS.get(key)                  
# &lt;end id=&quot;get-connection&quot;/&gt;


# 代码清单 10-2
# &lt;start id=&quot;get-sharded-connection&quot;/&gt;
def get_sharded_connection(component, key, shard_count, wait=1):
    # 计算出 “&lt;组件名&gt;:&lt;分片数字&gt;” 格式的分片 ID 。
    shard = shard_key(component, &#39;x&#39;+str(key), shard_count, 2)  
    # 返回连接。
    return get_redis_connection(shard, wait)                   
# &lt;end id=&quot;get-sharded-connection&quot;/&gt;


# &lt;start id=&quot;no-decorator-example&quot;/&gt;
def log_recent(conn, app, message):
    &#39;the old log_recent() code&#39;

log_recent = redis_connection(&#39;logs&#39;)(log_recent)   # 通过反复执行 3 次这行代码，可以达到和装饰器一样的效果
# &lt;end id=&quot;no-decorator-example&quot;/&gt;

# 代码清单 10-3
# &lt;start id=&quot;shard-aware-decorator&quot;/&gt;
# 装饰器接受组件名以及预期的分片数量作为参数。
def sharded_connection(component, shard_count, wait=1):        
    # 创建一个包装器，使用它去装饰传入的函数。
    def wrapper(function):                                     
        # 从原始函数里面复制一些有用的元信息到配置处理器。
        @functools.wraps(function)                            
        # 创建一个函数，它负责计算键的分片 ID ，并对连接管理器进行设置。
        def call(key, *args, **kwargs):                        
            # 获取分片连接。
            conn = get_sharded_connection(                     
                component, key, shard_count, wait)            
            # 实际地调用被装饰的函数，并将分片连接以及其他参数传递给它。
            return function(conn, key, *args, **kwargs)        
        # 返回被包装后的函数。
        return call                                             
    # 返回一个函数，它可以对需要分片连接的函数进行包装。
    return wrapper                                             
# &lt;end id=&quot;shard-aware-decorator&quot;/&gt;


# 代码清单 10-4
# &lt;start id=&quot;sharded-count-unique&quot;/&gt;
# 将 count_visit() 函数分片到 16 台机器上面执行，
# 执行所得的结果将被自动地分片到每台机器的多个数据库键上面。
@sharded_connection(&#39;unique&#39;, 16)                      
def count_visit(conn, session_id):
    today = date.today()
    key = &#39;unique:%s&#39;%today.isoformat()
    # 经过修改的 get_expected() 调用。
    conn2, expected = get_expected(key, today)        

    id = int(session_id.replace(&#39;-&#39;, &#39;&#39;)[:15], 16)
    if shard_sadd(conn, key, id, expected, SHARD_SIZE):
        # 使用 get_expected() 函数返回的非分片（nonsharded）连接，
        # 对唯一计数器执行自增操作。
        conn2.incr(key)                               

# 对 get_expected() 函数使用非分片连接。
@redis_connection(&#39;unique&#39;)                            
def get_expected(conn, key, today):
    &#39;all of the same function body as before, except the last line&#39;
    # 返回非分片连接，
    # 使得 count_visit() 函数可以在有需要的时候，
    # 对唯一计数器执行自增操作。
    return conn, EXPECTED[key]                        
# &lt;end id=&quot;sharded-count-unique&quot;/&gt;


# 代码清单 10-5
# &lt;start id=&quot;search-with-values&quot;/&gt;
# 这个函数接受的参数与 search_and_sort() 函数接受的参数完全相同。
def search_get_values(conn, query, id=None, ttl=300, sort=&quot;-updated&quot;, 
                      start=0, num=20):                               
    # 首先取得搜索操作和排序操作的执行结果。
    count, docids, id = search_and_sort(                           
        conn, query, id, ttl, sort, 0, start+num)                  

    key = &quot;kb:doc:%s&quot;
    sort = sort.lstrip(&#39;-&#39;)

    pipe = conn.pipeline(False)
    # 根据结果的排序方式来获取数据。
    for docid in docids:                                           
        pipe.hget(key%docid, sort)                                 
    sort_column = pipe.execute()                                   

    # 将文档 ID 以及对文档进行排序产生的数据进行配对（pair up）。
    data_pairs = zip(docids, sort_column)                          
    # 返回结果包含的文档数量、排序之后的搜索结果以及结果的缓存 ID 。
    return count, data_pairs, id                                   
# &lt;end id=&quot;search-with-values&quot;/&gt;


# 代码清单 10-6
# &lt;start id=&quot;search-on-shards&quot;/&gt;
# 程序为了获知自己要连接的服务器，
# 会假定所有分片服务器的信息都记录在一个标准的配置位置里面。
def get_shard_results(component, shards, query, ids=None, ttl=300,  
                  sort=&quot;-updated&quot;, start=0, num=20, wait=1):        

    # 准备一些结构，用于储存之后获取的数据。
    count = 0      
    data = []      
    # 尝试使用已被缓存的搜索结果；
    # 如果没有缓存结果可用，那么重新执行查询。
    ids = ids or shards * [None]       
    for shard in xrange(shards):
        # 获取或者创建一个连向指定分片的连接。
        conn = get_redis_connection(&#39;%s:%s&#39;%(component, shard), wait)
        # 获取搜索结果以及它们的排序数据。
        c, d, i = search_get_values(                        
            conn, query, ids[shard], ttl, sort, start, num) 

        # 将这个分片的计算结果与其他分片的计算结果进行合并。
        count += c          
        data.extend(d)     
        ids[shard] = i      

    # 把所有分片的原始（raw）计算结果返回给调用者。
    return count, data, ids    
# &lt;end id=&quot;search-on-shards&quot;/&gt;

def get_values_thread(component, shard, wait, rqueue, *args, **kwargs):
    conn = get_redis_connection(&#39;%s:%s&#39;%(component, shard), wait)
    count, results, id = search_get_values(conn, *args, **kwargs)
    rqueue.put((shard, count, results, id))

def get_shard_results_thread(component, shards, query, ids=None, ttl=300,
                  sort=&quot;-updated&quot;, start=0, num=20, wait=1, timeout=.5):

    ids = ids or shards * [None]
    rqueue = Queue()

    for shard in xrange(shards):
        t = threading.Thread(target=get_values_thread, args=(
            component, shard, wait, rqueue, query, ids[shard],
            ttl, sort, start, num))
        t.setDaemon(1)
        t.start()

    received = 0
    count = 0
    data = []
    deadline = time.time() + timeout
    while received &lt; shards and time.time() &lt; deadline:
        try:
            sh, c, r, i = rqueue.get(timeout=max(deadline-time.time(), .001))
        except Empty:
            break
        else:
            count += c
            data.extend(r)
            ids[sh] = i

    return count, data, ids


# 代码清单 10-7
# &lt;start id=&quot;merge-sharded-results&quot;/&gt;
def to_numeric_key(data):
    try:
        # 这里之所以使用 Decimal 数字类型，
        # 是因为这种类型可以合理地对整数和浮点数进行转换，
        # 并在值缺失或者不是数字值的时候，
        # 返回默认值 0 。
        return Decimal(data[1] or &#39;0&#39;)     
    except:
        return Decimal(&#39;0&#39;)               

def to_string_key(data):
    # 总是返回一个字符串，即使在值缺失的情况下，也是如此。
    return data[1] or &#39;&#39;                   

# 这个函数需要接受所有分片参数和搜索参数，
# 这些参数大部分都会被传给底层的函数，
# 而这个函数本身只会用到 sort 参数以及搜索偏移量。
def search_shards(component, shards, query, ids=None, ttl=300,     
                  sort=&quot;-updated&quot;, start=0, num=20, wait=1):       

    # 获取未经排序的分片搜索结果。
    count, data, ids = get_shard_results(                           
        component, shards, query, ids, ttl, sort, start, num, wait) 

    # 准备好进行排序所需的各个参数。
    reversed = sort.startswith(&#39;-&#39;)                    
    sort = sort.strip(&#39;-&#39;)                             
    key = to_numeric_key                               
    if sort not in (&#39;updated&#39;, &#39;id&#39;, &#39;created&#39;):        
        key = to_string_key                             

    # 根据 sort 参数对搜索结果进行排序。
    data.sort(key=key, reverse=reversed)               

    results = []
    # 只获取用户指定的那一页搜索结果。
    for docid, score in data[start:start+num]:         
        results.append(docid)                          

    # 返回被选中的结果，其中包括由每个分片的缓存 ID 组成的序列。
    return count, results, ids                         
# &lt;end id=&quot;merge-sharded-results&quot;/&gt;


# 代码清单 10-8
# &lt;start id=&quot;zset-search-with-values&quot;/&gt;
# 这个函数接受 search_and_zsort() 函数所需的全部参数。
def search_get_zset_values(conn, query, id=None, ttl=300, update=1, 
                    vote=0, start=0, num=20, desc=True):            

    # 调用底层的 search_and_zsort() 函数，
    # 获取搜索结果的缓存 ID 以及结果包含的文档数量。
    count, r, id = search_and_zsort(                                
        conn, query, id, ttl, update, vote, 0, 1, desc)             

    # 获取指定的搜索结果以及这些结果的分值。
    if desc:                                                        
        data = conn.zrevrange(id, 0, start + num - 1, withscores=True)
    else:                                                          
        data = conn.zrange(id, 0, start + num - 1, withscores=True) 

    # 返回搜索结果的数量、搜索结果本身、搜索结果的分值以及搜索结果的缓存 ID 。
    return count, data, id                                          
# &lt;end id=&quot;zset-search-with-values&quot;/&gt;


# 代码清单 10-9
# &lt;start id=&quot;search-shards-zset&quot;/&gt;
# 函数需要接受所有分片参数以及所有搜索参数。
def search_shards_zset(component, shards, query, ids=None, ttl=300,   
                update=1, vote=0, start=0, num=20, desc=True, wait=1):

    # 准备一些结构，用于储存之后获取到的数据。
    count = 0                       
    data = []                       
    # 尝试使用已有的缓存结果；
    # 如果没有缓存结果可用，那么开始一次新的搜索。
    ids = ids or shards * [None]    
    for shard in xrange(shards):
        # 获取或者创建指向每个分片的连接。
        conn = get_redis_connection(&#39;%s:%s&#39;%(component, shard), wait) 
        # 在分片上面进行搜索，并取得搜索结果的分值。
        c, d, i = search_get_zset_values(conn, query, ids[shard],     
            ttl, update, vote, start, num, desc)                      

        # 对每个分片的搜索结果进行合并。
        count += c      
        data.extend(d)  
        ids[shard] = i  

    # 定义一个简单的排序辅助函数，让它只返回与分值有关的信息。
    def key(result):       
        return result[1]   

    # 对所有搜索结果进行排序。
    data.sort(key=key, reversed=desc)   
    results = []
    # 从结果里面提取出文档 ID ，并丢弃与之关联的分值。
    for docid, score in data[start:start+num]:  
        results.append(docid)                  

    # 将搜索结果返回给调用者。
    return count, results, ids                  
# &lt;end id=&quot;search-shards-zset&quot;/&gt;


# 代码清单 10-11
# &lt;start id=&quot;sharded-api-base&quot;/&gt;
class KeyShardedConnection(object):
    # 对象使用组件名字以及分片数量进行初始化。
    def __init__(self, component, shards):        
        self.component = component                 
        self.shards = shards                      
    # 当用户尝试从对象里面获取一个元素的时候，
    # 这个方法就会被调用，
    # 而调用这个方法时传入的参数就是用户请求的元素。
    def __getitem__(self, key):                    
        # 根据传入的键以及之前已知的组件名字和分片数量，
        # 获取分片连接。
        return get_sharded_connection(             
            self.component, key, self.shards)     
# &lt;end id=&quot;sharded-api-base&quot;/&gt;


# 代码清单 10-10
# &lt;start id=&quot;sharded-api-example&quot;/&gt;
# 创建一个连接，这个连接包含对拥有指定分片数量的组件进行分片所需的相关信息。
sharded_timelines = KeyShardedConnection(&#39;timelines&#39;, 8)   

def follow_user(conn, uid, other_uid):
    fkey1 = &#39;following:%s&#39;%uid
    fkey2 = &#39;followers:%s&#39;%other_uid

    if conn.zscore(fkey1, other_uid):
        print &quot;already followed&quot;, uid, other_uid
        return None

    now = time.time()

    pipeline = conn.pipeline(True)
    pipeline.zadd(fkey1, other_uid, now)
    pipeline.zadd(fkey2, uid, now)
    pipeline.zcard(fkey1)
    pipeline.zcard(fkey2)
    following, followers = pipeline.execute()[-2:]
    pipeline.hset(&#39;user:%s&#39;%uid, &#39;following&#39;, following)
    pipeline.hset(&#39;user:%s&#39;%other_uid, &#39;followers&#39;, followers)
    pipeline.execute()

    pkey = &#39;profile:%s&#39;%other_uid
    # 从正在关注的用户的个人时间线里面，取出最新的状态消息。
    status_and_score = sharded_timelines[pkey].zrevrange(   
        pkey, 0, HOME_TIMELINE_SIZE-1, withscores=True)     

    if status_and_score:
        hkey = &#39;home:%s&#39;%uid
        # 根据被分片的键获取一个连接，然后通过连接获取一个流水线对象。
        pipe = sharded_timelines[hkey].pipeline(True)       
        # 将一系列状态消息添加到位于分片上面的定制时间线有序集合里面，
        # 并在添加操作完成之后，对有序集合进行修剪。
        pipe.zadd(hkey, **dict(status_and_score))           
        pipe.zremrangebyrank(hkey, 0, -HOME_TIMELINE_SIZE-1)
        # 执行事务。
        pipe.execute()                                      

    return True
# &lt;end id=&quot;sharded-api-example&quot;/&gt;


# 代码清单 10-13
# &lt;start id=&quot;key-data-sharded-api&quot;/&gt;
class KeyDataShardedConnection(object):
    # 对象使用组件名和分片数量进行初始化。
    def __init__(self, component, shards):         
        self.component = component                 
        self.shards = shards                       
    # 当一对 ID 作为字典查找操作的其中一个参数被传入时，
    # 这个方法将被调用。
    def __getitem__(self, ids):                   
        # 取出两个 ID ，并确保它们都是整数。
        id1, id2 = map(int, ids)                   
        # 如果第二个 ID 比第一个 ID 要小，
        # 那么对调两个 ID 的位置，
        # 从而确保第一个 ID 总是小于或等于第二个 ID 。
        if id2 &lt; id1:                              
            id1, id2 = id2, id1                    
        # 基于两个 ID 构建出一个键。
        key = &quot;%s:%s&quot;%(id1, id2)                    
        # 使用构建出的键以及之前已知的组件名和分片数量，
        # 获取分片连接。
        return get_sharded_connection(             
            self.component, key, self.shards)       
# &lt;end id=&quot;key-data-sharded-api&quot;/&gt;


_follow_user = follow_user
# 代码清单 10-12
# &lt;start id=&quot;sharded-api-example2&quot;/&gt;
# 创建一个连接，
# 这个连接包含对拥有指定分片数量的组件进行分片所需的相关信息。
sharded_timelines = KeyShardedConnection(&#39;timelines&#39;, 8)        
sharded_followers = KeyDataShardedConnection(&#39;followers&#39;, 16)   

def follow_user(conn, uid, other_uid):
    fkey1 = &#39;following:%s&#39;%uid
    fkey2 = &#39;followers:%s&#39;%other_uid

    # 根据 uid 和 other_uid 获取连接对象。
    sconn = sharded_followers[uid, other_uid]          
    # 检查 other_uid 代表的用户是否已经关注了 uid 代表的用户。
    if sconn.zscore(fkey1, other_uid):                 
        return None

    now = time.time()
    spipe = sconn.pipeline(True)
    # 把关注者的信息以及被关注者的信息添加到有序集合里面。
    spipe.zadd(fkey1, other_uid, now)                  
    spipe.zadd(fkey2, uid, now)                        
    following, followers = spipe.execute()

    pipeline = conn.pipeline(True)
    # 为执行关注操作的用户以及被关注的用户更新关注者信息和正在关注信息。
    pipeline.hincrby(&#39;user:%s&#39;%uid, &#39;following&#39;, int(following))      
    pipeline.hincrby(&#39;user:%s&#39;%other_uid, &#39;followers&#39;, int(followers))
    pipeline.execute()

    pkey = &#39;profile:%s&#39;%other_uid
    status_and_score = sharded_timelines[pkey].zrevrange(
        pkey, 0, HOME_TIMELINE_SIZE-1, withscores=True)

    if status_and_score:
        hkey = &#39;home:%s&#39;%uid
        pipe = sharded_timelines[hkey].pipeline(True)
        pipe.zadd(hkey, **dict(status_and_score))
        pipe.zremrangebyrank(hkey, 0, -HOME_TIMELINE_SIZE-1)
        pipe.execute()

    return True
# &lt;end id=&quot;sharded-api-example2&quot;/&gt;


# 代码清单 10-14
# &lt;start id=&quot;sharded-zrangebyscore&quot;/&gt;
# 函数接受组件名称、分片数量以及那些可以在分片环境下产生正确行为的参数作为参数。
def sharded_zrangebyscore(component, shards, key, min, max, num):  
    data = []
    for shard in xrange(shards):
        # 获取指向当前分片的分片连接。
        conn = get_redis_connection(&quot;%s:%s&quot;%(component, shard))     
        # 从 Redis 分片上面取出数据。
        data.extend(conn.zrangebyscore(                             
            key, min, max, start=0, num=num, withscores=True))      

    # 首先基于分值对数据进行排序，然后再基于成员进行排序。
    def key(pair):                     
        return pair[1], pair[0]        
    data.sort(key=key)                 

    # 根据用户请求的数量返回元素。
    return data[:num]                  
# &lt;end id=&quot;sharded-zrangebyscore&quot;/&gt;


# 代码清单 10-15
# &lt;start id=&quot;sharded-syndicate-posts&quot;/&gt;
def syndicate_status(uid, post, start=0, on_lists=False):
    root = &#39;followers&#39;
    key = &#39;followers:%s&#39;%uid
    base = &#39;home:%s&#39;
    if on_lists:
        root = &#39;list:out&#39;
        key = &#39;list:out:%s&#39;%uid
        base = &#39;list:statuses:%s&#39;

    # 通过 ZRANGEBYSCORE 调用，找出下一组关注者。
    followers = sharded_zrangebyscore(root,                         
        sharded_followers.shards, key, start, &#39;inf&#39;, POSTS_PER_PASS)

    # 基于预先分片的结果对个人信息进行分组，
    # 并把分组后的信息储存到预先准备好的结构里面。
    to_send = defaultdict(list)                            
    for follower, start in followers:
        # 构造出储存时间线的键。
        timeline = base % follower                          
        # 找到负责储存这个时间线的分片。
        shard = shard_key(&#39;timelines&#39;,                     
            timeline, sharded_timelines.shards, 2)         
        # 把时间线的键添加到位于同一个分片的其他时间线的后面。
        to_send[shard].append(timeline)                    

    for timelines in to_send.itervalues():
        # 根据储存这组时间线的服务器，
        # 找出连向它的连接，
        # 然后创建一个流水线对象。
        pipe = sharded_timelines[timelines[0]].pipeline(False) 
        for timeline in timelines:
            # 把新发送的消息添加到时间线上面，
            # 并移除过于陈旧的消息。
            pipe.zadd(timeline, **post)                
            pipe.zremrangebyrank(                      
                timeline, 0, -HOME_TIMELINE_SIZE-1)    
        pipe.execute()

    conn = redis.Redis()
    if len(followers) &gt;= POSTS_PER_PASS:
        execute_later(conn, &#39;default&#39;, &#39;syndicate_status&#39;,
            [uid, post, start, on_lists])

    elif not on_lists:
        execute_later(conn, &#39;default&#39;, &#39;syndicate_status&#39;,
            [uid, post, 0, True])
# &lt;end id=&quot;sharded-syndicate-posts&quot;/&gt;

def _fake_shards_for(conn, component, count, actual):
    assert actual &lt;= 4
    for i in xrange(count):
        m = i % actual
        conn.set(&#39;config:redis:%s:%i&#39;%(component, i), json.dumps({&#39;db&#39;:14 - m}))

class TestCh10(unittest.TestCase):
    def _flush(self):
        self.conn.flushdb()
        redis.Redis(db=14).flushdb()
        redis.Redis(db=13).flushdb()
        redis.Redis(db=12).flushdb()
        redis.Redis(db=11).flushdb()
        
    def setUp(self):
        self.conn = redis.Redis(db=15)
        self._flush()
        global config_connection
        config_connection = self.conn
        self.conn.set(&#39;config:redis:test&#39;, json.dumps({&#39;db&#39;:15}))

    def tearDown(self):
        self._flush()

    def test_get_sharded_connections(self):
        _fake_shards_for(self.conn, &#39;shard&#39;, 2, 2)

        for i in xrange(10):
            get_sharded_connection(&#39;shard&#39;, i, 2).sadd(&#39;foo&#39;, i)

        s0 = redis.Redis(db=14).scard(&#39;foo&#39;)
        s1 = redis.Redis(db=13).scard(&#39;foo&#39;)
        self.assertTrue(s0 &lt; 10)
        self.assertTrue(s1 &lt; 10)
        self.assertEquals(s0 + s1, 10)

    def test_count_visit(self):
        shards = {&#39;db&#39;:13}, {&#39;db&#39;:14}
        self.conn.set(&#39;config:redis:unique&#39;, json.dumps({&#39;db&#39;:15}))
        for i in xrange(16):
            self.conn.set(&#39;config:redis:unique:%s&#39;%i, json.dumps(shards[i&amp;1]))
    
        for i in xrange(100):
            count_visit(str(uuid.uuid4()))
        base = &#39;unique:%s&#39;%date.today().isoformat()
        total = 0
        for c in shards:
            conn = redis.Redis(**c)
            keys = conn.keys(base + &#39;:*&#39;)
            for k in keys:
                cnt = conn.scard(k)
                total += cnt
                self.assertTrue(cnt &lt; k)
        self.assertEquals(total, 100)
        self.assertEquals(self.conn.get(base), &#39;100&#39;)

    def test_sharded_search(self):
        _fake_shards_for(self.conn, &#39;search&#39;, 2, 2)
        
        docs = &#39;hello world how are you doing&#39;.split(), &#39;this world is doing fine&#39;.split()
        for i in xrange(50):
            c = get_sharded_connection(&#39;search&#39;, i, 2)
            index_document(c, i, docs[i&amp;1], {&#39;updated&#39;:time.time() + i, &#39;id&#39;:i, &#39;created&#39;:time.time() + i})
            r = search_and_sort(c, docs[i&amp;1], sort=&#39;-id&#39;)
            self.assertEquals(r[1][0], str(i))

        total = 0
        for shard in (0,1):
            count = search_get_values(get_redis_connection(&#39;search:%s&#39;%shard),[&#39;this&#39;, &#39;world&#39;], num=50)[0]
            total += count
            self.assertTrue(count &lt; 50)
            self.assertTrue(count &gt; 0)
        
        self.assertEquals(total, 25)
        
        count, r, id = get_shard_results(&#39;search&#39;, 2, [&#39;world&#39;, &#39;doing&#39;], num=50)
        self.assertEquals(count, 50)
        self.assertEquals(count, len(r))
        
        self.assertEquals(get_shard_results(&#39;search&#39;, 2, [&#39;this&#39;, &#39;doing&#39;], num=50)[0], 25)

        count, r, id = get_shard_results_thread(&#39;search&#39;, 2, [&#39;this&#39;, &#39;doing&#39;], num=50)
        self.assertEquals(count, 25)
        self.assertEquals(count, len(r))
        r.sort(key=lambda x:x[1], reverse=True)
        r = list(zip(*r)[0])
        
        count, r2, id = search_shards(&#39;search&#39;, 2, [&#39;this&#39;, &#39;doing&#39;])
        self.assertEquals(count, 25)
        self.assertEquals(len(r2), 20)
        self.assertEquals(r2, r[:20])
        
    def test_sharded_follow_user(self):
        _fake_shards_for(self.conn, &#39;timelines&#39;, 8, 4)

        sharded_timelines[&#39;profile:1&#39;].zadd(&#39;profile:1&#39;, 1, time.time())
        for u2 in xrange(2, 11):
            sharded_timelines[&#39;profile:%i&#39;%u2].zadd(&#39;profile:%i&#39;%u2, u2, time.time() + u2)
            _follow_user(self.conn, 1, u2)
            _follow_user(self.conn, u2, 1)
        
        self.assertEquals(self.conn.zcard(&#39;followers:1&#39;), 9)
        self.assertEquals(self.conn.zcard(&#39;following:1&#39;), 9)
        self.assertEquals(sharded_timelines[&#39;home:1&#39;].zcard(&#39;home:1&#39;), 9)
        
        for db in xrange(14, 10, -1):
            self.assertTrue(len(redis.Redis(db=db).keys()) &gt; 0)
        for u2 in xrange(2, 11):
            self.assertEquals(self.conn.zcard(&#39;followers:%i&#39;%u2), 1)
            self.assertEquals(self.conn.zcard(&#39;following:%i&#39;%u2), 1)
            self.assertEquals(sharded_timelines[&#39;home:%i&#39;%u2].zcard(&#39;home:%i&#39;%u2), 1)

    def test_sharded_follow_user_and_syndicate_status(self):
        _fake_shards_for(self.conn, &#39;timelines&#39;, 8, 4)
        _fake_shards_for(self.conn, &#39;followers&#39;, 4, 4)
        sharded_followers.shards = 4
    
        sharded_timelines[&#39;profile:1&#39;].zadd(&#39;profile:1&#39;, 1, time.time())
        for u2 in xrange(2, 11):
            sharded_timelines[&#39;profile:%i&#39;%u2].zadd(&#39;profile:%i&#39;%u2, u2, time.time() + u2)
            follow_user(self.conn, 1, u2)
            follow_user(self.conn, u2, 1)
        
        allkeys = defaultdict(int)
        for db in xrange(14, 10, -1):
            c = redis.Redis(db=db)
            for k in c.keys():
                allkeys[k] += c.zcard(k)

        for k, v in allkeys.iteritems():
            part, _, owner = k.partition(&#39;:&#39;)
            if part in (&#39;following&#39;, &#39;followers&#39;, &#39;home&#39;):
                self.assertEquals(v, 9 if owner == &#39;1&#39; else 1)
            elif part == &#39;profile&#39;:
                self.assertEquals(v, 1)

        self.assertEquals(len(sharded_zrangebyscore(&#39;followers&#39;, 4, &#39;followers:1&#39;, &#39;0&#39;, &#39;inf&#39;, 100)), 9)
        syndicate_status(1, {&#39;11&#39;:time.time()})
        self.assertEquals(len(sharded_zrangebyscore(&#39;timelines&#39;, 4, &#39;home:2&#39;, &#39;0&#39;, &#39;inf&#39;, 100)), 2)



if __name__ == &#39;__main__&#39;:
    unittest.main()
</pre></div>
</div>
</div>



            <div class="section" id="discuss">
    <h2>
        讨论
        <a class="headerlink" href="#discuss" title="永久链接至标题">¶</a>
    </h2>
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'redisinaction'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="chapter11.html" title="第 11 章相关源代码"
             >next</a> |</li>
        <li class="right" >
          <a href="chapter9.html" title="第 9 章相关源代码"
             >previous</a> |</li>
        <li><a href="../index.html">Redis 实战</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, 黄健宏（huangz）.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
    </div>
  </body>
</html>