<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>第 6 章相关源代码 &mdash; Redis 实战</title>
    
    <link rel="stylesheet" href="../_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Redis 实战" href="../index.html" />
    <link rel="next" title="第 7 章相关源代码" href="chapter7.html" />
    <link rel="prev" title="第 5 章相关源代码" href="chapter5.html" /> 

<!--[if lte IE 6]>
<link rel="stylesheet" href="../_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->


  </head>
  <body>


    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="chapter7.html" title="第 7 章相关源代码"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="chapter5.html" title="第 5 章相关源代码"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Redis 实战</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="id1">
<h1>第 6 章相关源代码<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="highlight-python"><div class="highlight"><pre># coding: utf-8

import bisect
from collections import defaultdict, deque
import json
import math
import os
import time
import unittest
import uuid
import zlib

import redis

QUIT = False
pipe = inv = item = buyer = seller = inventory = None


# 代码清单 6-1
# &lt;start id=&quot;_1314_14473_8380&quot;/&gt;
def add_update_contact(conn, user, contact):
    ac_list = &#39;recent:&#39; + user
    # 准备执行原子操作。
    pipeline = conn.pipeline(True) 
    # 如果联系人已经存在，那么移除他。
    pipeline.lrem(ac_list, contact) 
    # 将联系人推入到列表的最前端。
    pipeline.lpush(ac_list, contact) 
    # 只保留列表里面的前100个联系人。
    pipeline.ltrim(ac_list, 0, 99)   
    # 实际地执行以上操作。
    pipeline.execute()               
# &lt;end id=&quot;_1314_14473_8380&quot;/&gt;


# &lt;start id=&quot;_1314_14473_8383&quot;/&gt;
def remove_contact(conn, user, contact):
    conn.lrem(&#39;recent:&#39; + user, contact)
# &lt;end id=&quot;_1314_14473_8383&quot;/&gt;


# 代码清单 6-2
# &lt;start id=&quot;_1314_14473_8386&quot;/&gt;
def fetch_autocomplete_list(conn, user, prefix):
    # 获取自动补完列表。
    candidates = conn.lrange(&#39;recent:&#39; + user, 0, -1) 
    matches = []
    # 检查每个候选联系人。
    for candidate in candidates:                    
        if candidate.lower().startswith(prefix):  
            # 发现一个匹配的联系人。
            matches.append(candidate)         
    # 返回所有匹配的联系人。
    return matches                           
# &lt;end id=&quot;_1314_14473_8386&quot;/&gt;


# 代码清单 6-3
# &lt;start id=&quot;_1314_14473_8396&quot;/&gt;
# 准备一个由已知字符组成的列表。
valid_characters = &#39;`abcdefghijklmnopqrstuvwxyz{&#39;     

def find_prefix_range(prefix):
    # 在字符列表中查找前缀字符所处的位置。
    posn = bisect.bisect_left(valid_characters, prefix[-1:]) 
    # 找到前驱字符。
    suffix = valid_characters[(posn or 1) - 1]  
    # 返回范围。
    return prefix[:-1] + suffix + &#39;{&#39;, prefix + &#39;{&#39;         
# &lt;end id=&quot;_1314_14473_8396&quot;/&gt;


# 代码清单 6-4
# &lt;start id=&quot;_1314_14473_8399&quot;/&gt;
def autocomplete_on_prefix(conn, guild, prefix):
    # 根据给定的前缀计算出查找范围的起点和终点。
    start, end = find_prefix_range(prefix)              
    identifier = str(uuid.uuid4())                       
    start += identifier                                   
    end += identifier                                    
    zset_name = &#39;members:&#39; + guild

    # 将范围的起始元素和结束元素添加到有序集合里面。
    conn.zadd(zset_name, start, 0, end, 0)
    pipeline = conn.pipeline(True)
    while 1:
        try:
            pipeline.watch(zset_name)
            # 找到两个被插入元素在有序集合中的排名。
            sindex = pipeline.zrank(zset_name, start)      
            eindex = pipeline.zrank(zset_name, end)      
            erange = min(sindex + 9, eindex - 2)        
            pipeline.multi()
            # 获取范围内的值，然后删除之前插入的起始元素和结束元素。
            pipeline.zrem(zset_name, start, end)         
            pipeline.zrange(zset_name, sindex, erange)   
            items = pipeline.execute()[-1]             
            break
        # 如果自动补完有序集合已经被其他客户端修改过了，那么进行重试。
        except redis.exceptions.WatchError:               
            continue                                     

    # 如果有其他自动补完操作正在执行，
    # 那么从获取到的元素里面移除起始元素和终结元素。
    return [item for item in items if &#39;{&#39; not in item]  
# &lt;end id=&quot;_1314_14473_8399&quot;/&gt;


# 代码清单 6-5
# &lt;start id=&quot;_1314_14473_8403&quot;/&gt;
def join_guild(conn, guild, user):
    conn.zadd(&#39;members:&#39; + guild, user, 0)

def leave_guild(conn, guild, user):
    conn.zrem(&#39;members:&#39; + guild, user)
# &lt;end id=&quot;_1314_14473_8403&quot;/&gt;
#END


# 代码清单 6-6
# &lt;start id=&quot;_1314_14473_8431&quot;/&gt;
def list_item(conn, itemid, sellerid, price):
    #...
            # 监视卖家包裹发生的变动。
            pipe.watch(inv)                            
            # 确保被出售的物品仍然存在于卖家的包裹里面。
            if not pipe.sismember(inv, itemid):        
                pipe.unwatch()                        
                return None

            # 将物品添加到市场里面。
            pipe.multi()                          
            pipe.zadd(&quot;market:&quot;, item, price)     
            pipe.srem(inv, itemid)                 
            pipe.execute()                         
            return True
    #...
# &lt;end id=&quot;_1314_14473_8431&quot;/&gt;


# 代码清单 6-7
# &lt;start id=&quot;_1314_14473_8435&quot;/&gt;
def purchase_item(conn, buyerid, itemid, sellerid, lprice):
    #...
            # 监视市场以及买家个人信息发生的变化。
            pipe.watch(&quot;market:&quot;, buyer)             

            # 检查物品是否已经售出、物品的价格是否已经发生了变化，
            # 以及买家是否有足够的金钱来购买这件物品。
            price = pipe.zscore(&quot;market:&quot;, item)     
            funds = int(pipe.hget(buyer, &#39;funds&#39;))    
            if price != lprice or price &gt; funds:     
                pipe.unwatch()                       
                return None

            # 将买家支付的货款转移给卖家，并将被卖出的物品转移给买家。
            pipe.multi()                              
            pipe.hincrby(seller, &#39;funds&#39;, int(price)) 
            pipe.hincrby(buyerid, &#39;funds&#39;, int(-price))
            pipe.sadd(inventory, itemid)               
            pipe.zrem(&quot;market:&quot;, item)                 
            pipe.execute()                            
            return True

    #...
# &lt;end id=&quot;_1314_14473_8435&quot;/&gt;


# 代码清单 6-8
# &lt;start id=&quot;_1314_14473_8641&quot;/&gt;
def acquire_lock(conn, lockname, acquire_timeout=10):
    # 128位随机标识符。
    identifier = str(uuid.uuid4())                     

    end = time.time() + acquire_timeout
    while time.time() &lt; end:
        # 尝试取得锁。
        if conn.setnx(&#39;lock:&#39; + lockname, identifier): 
            return identifier

        time.sleep(.001)

    return False
# &lt;end id=&quot;_1314_14473_8641&quot;/&gt;


# 代码清单 6-9
# &lt;start id=&quot;_1314_14473_8645&quot;/&gt;
def purchase_item_with_lock(conn, buyerid, itemid, sellerid):
    buyer = &quot;users:%s&quot; % buyerid
    seller = &quot;users:%s&quot; % sellerid
    item = &quot;%s.%s&quot; % (itemid, sellerid)
    inventory = &quot;inventory:%s&quot; % buyerid

    # 尝试获取锁。
    locked = acquire_lock(conn, &#39;market:&#39;)   
    if not locked:
        return False

    pipe = conn.pipeline(True)
    try:
        # 检查物品是否已经售出，以及买家是否有足够的金钱来购买物品。
        pipe.zscore(&quot;market:&quot;, item)        
        pipe.hget(buyer, &#39;funds&#39;)            
        price, funds = pipe.execute()         
        if price is None or price &gt; funds:   
            return None                     

        # 将买家支付的货款转移给卖家，并将售出的物品转移给买家。
        pipe.hincrby(seller, &#39;funds&#39;, int(price)) 
        pipe.hincrby(buyer, &#39;funds&#39;, int(-price)) 
        pipe.sadd(inventory, itemid)            
        pipe.zrem(&quot;market:&quot;, item)               
        pipe.execute()                           
        return True
    finally:
        # 释放锁。
        release_lock(conn, &#39;market:&#39;, locked)   
# &lt;end id=&quot;_1314_14473_8645&quot;/&gt;


# 代码清单 6-10
# &lt;start id=&quot;_1314_14473_8650&quot;/&gt;
def release_lock(conn, lockname, identifier):
    pipe = conn.pipeline(True)
    lockname = &#39;lock:&#39; + lockname

    while True:
        try:
            # 检查并确认进程还持有着锁。
            pipe.watch(lockname)                  
            if pipe.get(lockname) == identifier:  
                # 释放锁。
                pipe.multi()                  
                pipe.delete(lockname)      
                pipe.execute()             
                return True                    

            pipe.unwatch()
            break

        # 有其他客户端修改了锁；重试。
        except redis.exceptions.WatchError:     
            pass                                 

    # 进程已经失去了锁。
    return False                                
# &lt;end id=&quot;_1314_14473_8650&quot;/&gt;


# 代码清单 6-11
# &lt;start id=&quot;_1314_14473_8790&quot;/&gt;
def acquire_lock_with_timeout(
    conn, lockname, acquire_timeout=10, lock_timeout=10):
    # 128位随机标识符。
    identifier = str(uuid.uuid4())                   
    lockname = &#39;lock:&#39; + lockname
    # 确保传给EXPIRE的都是整数。
    lock_timeout = int(math.ceil(lock_timeout))     

    end = time.time() + acquire_timeout
    while time.time() &lt; end:
        # 获取锁并设置过期时间。
        if conn.setnx(lockname, identifier):        
            conn.expire(lockname, lock_timeout)    
            return identifier
        # 检查过期时间，并在有需要时对其进行更新。
        elif not conn.ttl(lockname):                 
            conn.expire(lockname, lock_timeout)   

        time.sleep(.001)

    return False
# &lt;end id=&quot;_1314_14473_8790&quot;/&gt;


# 代码清单 6-12 
# &lt;start id=&quot;_1314_14473_8986&quot;/&gt;
def acquire_semaphore(conn, semname, limit, timeout=10):
    # 128位随机标识符。
    identifier = str(uuid.uuid4())                         
    now = time.time()

    pipeline = conn.pipeline(True)
    # 清理过期的信号量持有者。
    pipeline.zremrangebyscore(semname, &#39;-inf&#39;, now - timeout) 
    # 尝试获取信号量。
    pipeline.zadd(semname, identifier, now)                 
    # 检查是否成功取得了信号量。
    pipeline.zrank(semname, identifier)              
    if pipeline.execute()[-1] &lt; limit:                        
        return identifier

    # 获取信号量失败，删除之前添加的标识符。
    conn.zrem(semname, identifier)                            
    return None
# &lt;end id=&quot;_1314_14473_8986&quot;/&gt;


# 代码清单 6-13
# &lt;start id=&quot;_1314_14473_8990&quot;/&gt;
def release_semaphore(conn, semname, identifier):
    # 如果信号量已经被正确地释放，那么返回True；
    # 返回False则表示该信号量已经因为过期而被删除了。
    return conn.zrem(semname, identifier)                   
# &lt;end id=&quot;_1314_14473_8990&quot;/&gt;


# 代码清单 6-14
# &lt;start id=&quot;_1314_14473_9004&quot;/&gt;
def acquire_fair_semaphore(conn, semname, limit, timeout=10):
    # 128位随机标识符。
    identifier = str(uuid.uuid4())                           
    czset = semname + &#39;:owner&#39;
    ctr = semname + &#39;:counter&#39;

    now = time.time()
    pipeline = conn.pipeline(True)
    # 删除超时的信号量。
    pipeline.zremrangebyscore(semname, &#39;-inf&#39;, now - timeout)  
    pipeline.zinterstore(czset, {czset: 1, semname: 0})      

    # 对计数器执行自增操作，并获取操作执行之后的值。
    pipeline.incr(ctr)                                       
    counter = pipeline.execute()[-1]                         

    # 尝试获取信号量。
    pipeline.zadd(semname, identifier, now)                   
    pipeline.zadd(czset, identifier, counter)                

    # 通过检查排名来判断客户端是否取得了信号量。
    pipeline.zrank(czset, identifier)                         
    if pipeline.execute()[-1] &lt; limit:                       
        # 客户端成功取得了信号量。
        return identifier                                    

    # 客户端未能取得信号量，清理无用数据。
    pipeline.zrem(semname, identifier)                        
    pipeline.zrem(czset, identifier)                         
    pipeline.execute()
    return None
# &lt;end id=&quot;_1314_14473_9004&quot;/&gt;


# 代码清单 6-15
# &lt;start id=&quot;_1314_14473_9014&quot;/&gt;
def release_fair_semaphore(conn, semname, identifier):
    pipeline = conn.pipeline(True)
    pipeline.zrem(semname, identifier)
    pipeline.zrem(semname + &#39;:owner&#39;, identifier)
    # 返回True表示信号量已被正确地释放，
    # 返回False则表示想要释放的信号量已经因为超时而被删除了。
    return pipeline.execute()[0]                             
# &lt;end id=&quot;_1314_14473_9014&quot;/&gt;


# 代码清单 6-16
# &lt;start id=&quot;_1314_14473_9022&quot;/&gt;
def refresh_fair_semaphore(conn, semname, identifier):
    # 更新客户端持有的信号量。
    if conn.zadd(semname, identifier, time.time()):          
        # 告知调用者，客户端已经失去了信号量。
        release_fair_semaphore(conn, semname, identifier)   
        return False                                      
    # 客户端仍然持有信号量。
    return True                                              
# &lt;end id=&quot;_1314_14473_9022&quot;/&gt;


# 代码清单 6-17
# &lt;start id=&quot;_1314_14473_9031&quot;/&gt;
def acquire_semaphore_with_lock(conn, semname, limit, timeout=10):
    identifier = acquire_lock(conn, semname, acquire_timeout=.01)
    if identifier:
        try:
            return acquire_fair_semaphore(conn, semname, limit, timeout)
        finally:
            release_lock(conn, semname, identifier)
# &lt;end id=&quot;_1314_14473_9031&quot;/&gt;


# 代码清单 6-18
# &lt;start id=&quot;_1314_14473_9056&quot;/&gt;
def send_sold_email_via_queue(conn, seller, item, price, buyer):
    # 准备好待发送邮件。
    data = {
        &#39;seller_id&#39;: seller,                 
        &#39;item_id&#39;: item,                      
        &#39;price&#39;: price,                         
        &#39;buyer_id&#39;: buyer,                      
        &#39;time&#39;: time.time()                    
    }
    # 将待发送邮件推入到队列里面。
    conn.rpush(&#39;queue:email&#39;, json.dumps(data)) 
# &lt;end id=&quot;_1314_14473_9056&quot;/&gt;


# 代码清单 6-19
# &lt;start id=&quot;_1314_14473_9060&quot;/&gt;
def process_sold_email_queue(conn):
    while not QUIT:
        # 尝试获取一封待发送邮件。
        packed = conn.blpop([&#39;queue:email&#39;], 30)                  
        # 队列里面暂时还没有待发送邮件，重试。
        if not packed:                                          
            continue

        # 从JSON对象中解码出邮件信息。
        to_send = json.loads(packed[1])                       
        try:
            # 使用预先编写好的邮件发送函数来发送邮件。
            fetch_data_and_send_sold_email(to_send)            
        except EmailSendError as err:
            log_error(&quot;Failed to send sold email&quot;, err, to_send)
        else:
            log_success(&quot;Sent sold email&quot;, to_send)
# &lt;end id=&quot;_1314_14473_9060&quot;/&gt;


# 代码清单 6-20
# &lt;start id=&quot;_1314_14473_9066&quot;/&gt;
def worker_watch_queue(conn, queue, callbacks):
    while not QUIT:
        # 尝试从队列里面取出一项待执行任务。
        packed = conn.blpop([queue], 30)                   
        # 队列为空，没有任务需要执行；重试。
        if not packed:                                     
            continue                                      

        # 解码任务信息。
        name, args = json.loads(packed[1])                
        # 没有找到任务指定的回调函数，用日志记录错误并重试。
        if name not in callbacks:                         
            log_error(&quot;Unknown callback %s&quot;%name)        
            continue                                      
        # 执行任务。
        callbacks[name](*args)                            
# &lt;end id=&quot;_1314_14473_9066&quot;/&gt;


# 代码清单 6-21
# &lt;start id=&quot;_1314_14473_9074&quot;/&gt;
def worker_watch_queues(conn, queues, callbacks):   # 实现优先级特性要修改的第一行代码。
    while not QUIT:
        packed = conn.blpop(queues, 30)             # 实现优先级特性要修改的第二行代码。
        if not packed:
            continue

        name, args = json.loads(packed[1])
        if name not in callbacks:
            log_error(&quot;Unknown callback %s&quot;%name)
            continue
        callbacks[name](*args)
# &lt;end id=&quot;_1314_14473_9074&quot;/&gt;


# 代码清单 6-22
# &lt;start id=&quot;_1314_14473_9094&quot;/&gt;
def execute_later(conn, queue, name, args, delay=0):
    # 创建唯一标识符。
    identifier = str(uuid.uuid4())                        
    # 准备好需要入队的任务。
    item = json.dumps([identifier, queue, name, args])  
    if delay &gt; 0:
        # 延迟执行这个任务。
        conn.zadd(&#39;delayed:&#39;, item, time.time() + delay) 
    else:
        # 立即执行这个任务。
        conn.rpush(&#39;queue:&#39; + queue, item)                 
    # 返回标识符。
    return identifier                                    
# &lt;end id=&quot;_1314_14473_9094&quot;/&gt;


# 代码清单 6-23
# &lt;start id=&quot;_1314_14473_9099&quot;/&gt;
def poll_queue(conn):
    while not QUIT:
        # 获取队列中的第一个任务。
        item = conn.zrange(&#39;delayed:&#39;, 0, 0, withscores=True)   
        # 队列没有包含任何任务，或者任务的执行时间未到。
        if not item or item[0][1] &gt; time.time():               
            time.sleep(.01)                                    
            continue                                            

        # 解码要被执行的任务，弄清楚它应该被推入到哪个任务队列里面。
        item = item[0][0]                                      
        identifier, queue, function, args = json.loads(item)   

        # 为了对任务进行移动，尝试获取锁。
        locked = acquire_lock(conn, identifier)                
        # 获取锁失败，跳过后续步骤并重试。
        if not locked:                                         
            continue                                          

        # 将任务推入到适当的任务队列里面。
        if conn.zrem(&#39;delayed:&#39;, item):                       
            conn.rpush(&#39;queue:&#39; + queue, item)                 

        # 释放锁。
        release_lock(conn, identifier, locked)                 
# &lt;end id=&quot;_1314_14473_9099&quot;/&gt;


# 代码清单 6-24
# &lt;start id=&quot;_1314_14473_9124&quot;/&gt;
def create_chat(conn, sender, recipients, message, chat_id=None):
    # 获得新的群组ID。
    chat_id = chat_id or str(conn.incr(&#39;ids:chat:&#39;))     

    # 创建一个由用户和分值组成的字典，字典里面的信息将被添加到有序集合里面。
    recipients.append(sender)                           
    recipientsd = dict((r, 0) for r in recipients)       

    pipeline = conn.pipeline(True)
    # 将所有参与群聊的用户添加到有序集合里面。
    pipeline.zadd(&#39;chat:&#39; + chat_id, **recipientsd)      
    # 初始化已读有序集合。
    for rec in recipients:                                
        pipeline.zadd(&#39;seen:&#39; + rec, chat_id, 0)          
    pipeline.execute()

    # 发送消息。
    return send_message(conn, chat_id, sender, message)  
# &lt;end id=&quot;_1314_14473_9124&quot;/&gt;


# 代码清单 6-25
# &lt;start id=&quot;_1314_14473_9127&quot;/&gt;
def send_message(conn, chat_id, sender, message):
    identifier = acquire_lock(conn, &#39;chat:&#39; + chat_id)
    if not identifier:
        raise Exception(&quot;Couldn&#39;t get the lock&quot;)
    try:
        # 筹备待发送的消息。
        mid = conn.incr(&#39;ids:&#39; + chat_id) 
        ts = time.time()                                 
        packed = json.dumps({                            
            &#39;id&#39;: mid,                                   
            &#39;ts&#39;: ts,                                   
            &#39;sender&#39;: sender,                           
            &#39;message&#39;: message,                         
        })                                              

        # 将消息发送至群组。
        conn.zadd(&#39;msgs:&#39; + chat_id, packed, mid)     
    finally:
        release_lock(conn, &#39;chat:&#39; + chat_id, identifier)
    return chat_id
# &lt;end id=&quot;_1314_14473_9127&quot;/&gt;


# 代码清单 6-26
# &lt;start id=&quot;_1314_14473_9132&quot;/&gt;
def fetch_pending_messages(conn, recipient):
    # 获取最后接收到的消息的ID。
    seen = conn.zrange(&#39;seen:&#39; + recipient, 0, -1, withscores=True) 

    pipeline = conn.pipeline(True)

    # 获取所有未读消息。
    for chat_id, seen_id in seen:                              
        pipeline.zrangebyscore(                              
            &#39;msgs:&#39; + chat_id, seen_id+1, &#39;inf&#39;)               
    # 这些数据将被返回给函数调用者。
    chat_info = zip(seen, pipeline.execute())                 

    for i, ((chat_id, seen_id), messages) in enumerate(chat_info):
        if not messages:
            continue
        messages[:] = map(json.loads, messages)
        # 使用最新收到的消息来更新群组有序集合。
        seen_id = messages[-1][&#39;id&#39;]                         
        conn.zadd(&#39;chat:&#39; + chat_id, recipient, seen_id)       

        # 找出那些所有人都已经阅读过的消息。
        min_id = conn.zrange(                                
            &#39;chat:&#39; + chat_id, 0, 0, withscores=True)          

        # 更新已读消息有序集合。
        pipeline.zadd(&#39;seen:&#39; + recipient, chat_id, seen_id)   
        if min_id:
            # 清除那些已经被所有人阅读过的消息。
            pipeline.zremrangebyscore(                        
                &#39;msgs:&#39; + chat_id, 0, min_id[0][1])             
        chat_info[i] = (chat_id, messages)
    pipeline.execute()

    return chat_info
# &lt;end id=&quot;_1314_14473_9132&quot;/&gt;


# 代码清单 2-27
# &lt;start id=&quot;_1314_14473_9135&quot;/&gt;
def join_chat(conn, chat_id, user):
    # 取得最新群组消息的ID。
    message_id = int(conn.get(&#39;ids:&#39; + chat_id))            

    pipeline = conn.pipeline(True)
    # 将用户添加到群组成员列表里面。
    pipeline.zadd(&#39;chat:&#39; + chat_id, user, message_id)         
    # 将群组添加到用户的已读列表里面。
    pipeline.zadd(&#39;seen:&#39; + user, chat_id, message_id)        
    pipeline.execute()
# &lt;end id=&quot;_1314_14473_9135&quot;/&gt;


# 代码清单 2-28
# &lt;start id=&quot;_1314_14473_9136&quot;/&gt;
def leave_chat(conn, chat_id, user):
    pipeline = conn.pipeline(True)
    # 从群组里面移除给定的用户。
    pipeline.zrem(&#39;chat:&#39; + chat_id, user)                     
    pipeline.zrem(&#39;seen:&#39; + user, chat_id)                     
    # 查看群组剩余成员的数量。
    pipeline.zcard(&#39;chat:&#39; + chat_id)                          

    if not pipeline.execute()[-1]:
        # 删除群组。
        pipeline.delete(&#39;msgs:&#39; + chat_id)                    
        pipeline.delete(&#39;ids:&#39; + chat_id)                     
        pipeline.execute()
    else:
        # 查找那些已经被所有成员阅读过的消息。
        oldest = conn.zrange(                                  
            &#39;chat:&#39; + chat_id, 0, 0, withscores=True)          
        # 删除那些已经被所有成员阅读过的消息。
        conn.zremrangebyscore(&#39;chat:&#39; + chat_id, 0, oldest[0][1])    
# &lt;end id=&quot;_1314_14473_9136&quot;/&gt;


# 代码清单 2-29
# &lt;start id=&quot;_1314_15044_3669&quot;/&gt;
# 本地聚合数据字典。
aggregates = defaultdict(lambda: defaultdict(int))     

def daily_country_aggregate(conn, line):
    if line:
        line = line.split()
        # 提取日志行中的信息。
        ip = line[0]                                    
        day = line[1]                                   
        # 根据IP地址判断用户所在国家。
        country = find_city_by_ip_local(ip)[2]        
        # 对本地聚合数据执行自增操作。
        aggregates[day][country] += 1                  
        return

    # 当天的日志文件已经处理完毕，将聚合计算的结果写入到Redis里面。
    for day, aggregate in aggregates.items():          
        conn.zadd(&#39;daily:country:&#39; + day, **aggregate) 
        del aggregates[day]                           
# &lt;end id=&quot;_1314_15044_3669&quot;/&gt;


# 代码清单 2-30
# &lt;start id=&quot;_1314_14473_9209&quot;/&gt;
def copy_logs_to_redis(conn, path, channel, count=10,
                       limit=2**30, quit_when_done=True):
    bytes_in_redis = 0
    waiting = deque()
    # 创建用于向客户端发送消息的群组。
    create_chat(conn, &#39;source&#39;, map(str, range(count)), &#39;&#39;, channel) 
    count = str(count)
    # 遍历所有日志文件。
    for logfile in sorted(os.listdir(path)):             
        full_path = os.path.join(path, logfile)

        fsize = os.stat(full_path).st_size
        # 如果程序需要更多空间，那么清除已经处理完毕的文件。
        while bytes_in_redis + fsize &gt; limit:              
            cleaned = _clean(conn, channel, waiting, count)
            if cleaned:                                  
                bytes_in_redis -= cleaned                
            else:                                       
                time.sleep(.25)                          

        # 将文件上传至Redis。
        with open(full_path, &#39;rb&#39;) as inp:           
            block = &#39; &#39;                          
            while block:                                 
                block = inp.read(2**17)                  
                conn.append(channel+logfile, block)      

        # 提醒监听者，文件已经准备就绪。
        send_message(conn, channel, &#39;source&#39;, logfile)    

        # 对本地记录的Redis内存占用量相关信息进行更新。
        bytes_in_redis += fsize                          
        waiting.append((logfile, fsize))                  

    # 所有日志文件已经处理完毕，向监听者报告此事。
    if quit_when_done:                                    
        send_message(conn, channel, &#39;source&#39;, &#39;:done&#39;)    

    # 在工作完成之后，清理无用的日志文件。
    while waiting:                                        
        cleaned = _clean(conn, channel, waiting, count)   
        if cleaned:                                       
            bytes_in_redis -= cleaned                     
        else:                                             
            time.sleep(.25)                             

# 对Redis进行清理的详细步骤。
def _clean(conn, channel, waiting, count):                
    if not waiting:                                        
        return 0                                           
    w0 = waiting[0][0]                                     
    if conn.get(channel + w0 + &#39;:done&#39;) == count:          
        conn.delete(channel + w0, channel + w0 + &#39;:done&#39;)  
        return waiting.popleft()[1]                        
    return 0                                               
# &lt;end id=&quot;_1314_14473_9209&quot;/&gt;


# 代码清单 6-31
# &lt;start id=&quot;_1314_14473_9213&quot;/&gt;
def process_logs_from_redis(conn, id, callback):
    while 1:
        # 获取文件列表。
        fdata = fetch_pending_messages(conn, id)                    

        for ch, mdata in fdata:
            for message in mdata:
                logfile = message[&#39;message&#39;]

                # 所有日志行已经处理完毕。
                if logfile == &#39;:done&#39;:                                
                    return                                            
                elif not logfile:
                    continue

                # 选择一个块读取器（block reader）。
                block_reader = readblocks                             
                if logfile.endswith(&#39;.gz&#39;):                           
                    block_reader = readblocks_gz                      

                # 遍历日志行。
                for line in readlines(conn, ch+logfile, block_reader):
                    # 将日志行传递给回调函数。
                    callback(conn, line)                              
                # 强制地刷新聚合数据缓存。
                callback(conn, None)                                 

                # 报告日志已经处理完毕。
                conn.incr(ch + logfile + &#39;:done&#39;)                    

        if not fdata:
            time.sleep(.1)
# &lt;end id=&quot;_1314_14473_9213&quot;/&gt;


# 代码清单 6-32
# &lt;start id=&quot;_1314_14473_9221&quot;/&gt;
def readlines(conn, key, rblocks):
    out = &#39;&#39;
    for block in rblocks(conn, key):
        out += block
        # 查找位于文本最右端的断行符；如果断行符不存在，那么rfind()返回-1。
        posn = out.rfind(&#39;\n&#39;)                      
        # 找到一个断行符。
        if posn &gt;= 0:                               
            # 根据断行符来分割日志行。
            for line in out[:posn].split(&#39;\n&#39;):    
                # 向调用者返回每个行。
                yield line + &#39;\n&#39;                  
            # 保留余下的数据。
            out = out[posn+1:]                     
        # 所有数据块已经处理完毕。
        if not block:                              
            yield out
            break
# &lt;end id=&quot;_1314_14473_9221&quot;/&gt;


# 代码清单 6-33
# &lt;start id=&quot;_1314_14473_9225&quot;/&gt;
def readblocks(conn, key, blocksize=2**17):
    lb = blocksize
    pos = 0
    # 尽可能地读取更多数据，直到出现不完整读操作（partial read）为止。
    while lb == blocksize:                                 
        # 获取数据块。
        block = conn.substr(key, pos, pos + blocksize - 1) 
        # 准备进行下一次遍历。
        yield block                                        
        lb = len(block)                                    
        pos += lb                                          
    yield &#39;&#39;
# &lt;end id=&quot;_1314_14473_9225&quot;/&gt;


# 代码清单 6-34
# &lt;start id=&quot;_1314_14473_9229&quot;/&gt;
def readblocks_gz(conn, key):
    inp = &#39;&#39;
    decoder = None
    # 从Redis里面读入原始数据。
    for block in readblocks(conn, key, 2**17):                 
        if not decoder:
            inp += block
            try:
                # 分析头信息以便取得被压缩数据。
                if inp[:3] != &quot;\x1f\x8b\x08&quot;:                
                    raise IOError(&quot;invalid gzip data&quot;)         
                i = 10                                          
                flag = ord(inp[3])                              
                if flag &amp; 4:                                    
                    i += 2 + ord(inp[i]) + 256*ord(inp[i+1])    
                if flag &amp; 8:                                    
                    i = inp.index(&#39;\0&#39;, i) + 1                  
                if flag &amp; 16:                                   
                    i = inp.index(&#39;\0&#39;, i) + 1                  
                if flag &amp; 2:                                   
                    i += 2                                     

                # 程序读取的头信息并不完整。
                if i &gt; len(inp):                               
                    raise IndexError(&quot;not enough data&quot;)         
            except (IndexError, ValueError):                    
                continue                                       

            else:
                # 已经找到头信息，准备好相应的解压程序。
                block = inp[i:]                                 
                inp = None                                      
                decoder = zlib.decompressobj(-zlib.MAX_WBITS)   
                if not block:
                    continue

        # 所有数据已经处理完毕，向调用者返回最后剩下的数据块。
        if not block:                                           
            yield decoder.flush()                               
            break

        # 向调用者返回解压后的数据块。
        yield decoder.decompress(block)                         
# &lt;end id=&quot;_1314_14473_9229&quot;/&gt;

class TestCh06(unittest.TestCase):
    def setUp(self):
        import redis
        self.conn = redis.Redis(db=15)

    def tearDown(self):
        self.conn.flushdb()
        del self.conn
        print
        print

    def test_add_update_contact(self):
        import pprint
        conn = self.conn
        conn.delete(&#39;recent:user&#39;)

        print &quot;Let&#39;s add a few contacts...&quot;
        for i in xrange(10):
            add_update_contact(conn, &#39;user&#39;, &#39;contact-%i-%i&#39;%(i//3, i))
        print &quot;Current recently contacted contacts&quot;
        contacts = conn.lrange(&#39;recent:user&#39;, 0, -1)
        pprint.pprint(contacts)
        self.assertTrue(len(contacts) &gt;= 10)
        print

        print &quot;Let&#39;s pull one of the older ones up to the front&quot;
        add_update_contact(conn, &#39;user&#39;, &#39;contact-1-4&#39;)
        contacts = conn.lrange(&#39;recent:user&#39;, 0, 2)
        print &quot;New top-3 contacts:&quot;
        pprint.pprint(contacts)
        self.assertEquals(contacts[0], &#39;contact-1-4&#39;)
        print

        print &quot;Let&#39;s remove a contact...&quot;
        print remove_contact(conn, &#39;user&#39;, &#39;contact-2-6&#39;)
        contacts = conn.lrange(&#39;recent:user&#39;, 0, -1)
        print &quot;New contacts:&quot;
        pprint.pprint(contacts)
        self.assertTrue(len(contacts) &gt;= 9)
        print

        print &quot;And let&#39;s finally autocomplete on &quot;
        all = conn.lrange(&#39;recent:user&#39;, 0, -1)
        contacts = fetch_autocomplete_list(conn, &#39;user&#39;, &#39;c&#39;)
        self.assertTrue(all == contacts)
        equiv = [c for c in all if c.startswith(&#39;contact-2-&#39;)]
        contacts = fetch_autocomplete_list(conn, &#39;user&#39;, &#39;contact-2-&#39;)
        equiv.sort()
        contacts.sort()
        self.assertEquals(equiv, contacts)
        conn.delete(&#39;recent:user&#39;)

    def test_address_book_autocomplete(self):
        self.conn.delete(&#39;members:test&#39;)
        print &quot;the start/end range of &#39;abc&#39; is:&quot;, find_prefix_range(&#39;abc&#39;)
        print

        print &quot;Let&#39;s add a few people to the guild&quot;
        for name in [&#39;jeff&#39;, &#39;jenny&#39;, &#39;jack&#39;, &#39;jennifer&#39;]:
            join_guild(self.conn, &#39;test&#39;, name)
        print
        print &quot;now let&#39;s try to find users with names starting with &#39;je&#39;:&quot;
        r = autocomplete_on_prefix(self.conn, &#39;test&#39;, &#39;je&#39;)
        print r
        self.assertTrue(len(r) == 3)
        print &quot;jeff just left to join a different guild...&quot;
        leave_guild(self.conn, &#39;test&#39;, &#39;jeff&#39;)
        r = autocomplete_on_prefix(self.conn, &#39;test&#39;, &#39;je&#39;)
        print r
        self.assertTrue(len(r) == 2)
        self.conn.delete(&#39;members:test&#39;)

    def test_distributed_locking(self):
        self.conn.delete(&#39;lock:testlock&#39;)
        print &quot;Getting an initial lock...&quot;
        self.assertTrue(acquire_lock_with_timeout(self.conn, &#39;testlock&#39;, 1, 1))
        print &quot;Got it!&quot;
        print &quot;Trying to get it again without releasing the first one...&quot;
        self.assertFalse(acquire_lock_with_timeout(self.conn, &#39;testlock&#39;, .01, 1))
        print &quot;Failed to get it!&quot;
        print
        print &quot;Waiting for the lock to timeout...&quot;
        time.sleep(2)
        print &quot;Getting the lock again...&quot;
        r = acquire_lock_with_timeout(self.conn, &#39;testlock&#39;, 1, 1)
        self.assertTrue(r)
        print &quot;Got it!&quot;
        print &quot;Releasing the lock...&quot;
        self.assertTrue(release_lock(self.conn, &#39;testlock&#39;, r))
        print &quot;Released it...&quot;
        print
        print &quot;Acquiring it again...&quot;
        self.assertTrue(acquire_lock_with_timeout(self.conn, &#39;testlock&#39;, 1, 1))
        print &quot;Got it!&quot;
        self.conn.delete(&#39;lock:testlock&#39;)

    def test_counting_semaphore(self):
        self.conn.delete(&#39;testsem&#39;, &#39;testsem:owner&#39;, &#39;testsem:counter&#39;)
        print &quot;Getting 3 initial semaphores with a limit of 3...&quot;
        for i in xrange(3):
            self.assertTrue(acquire_fair_semaphore(self.conn, &#39;testsem&#39;, 3, 1))
        print &quot;Done!&quot;
        print &quot;Getting one more that should fail...&quot;
        self.assertFalse(acquire_fair_semaphore(self.conn, &#39;testsem&#39;, 3, 1))
        print &quot;Couldn&#39;t get it!&quot;
        print
        print &quot;Lets&#39;s wait for some of them to time out&quot;
        time.sleep(2)
        print &quot;Can we get one?&quot;
        r = acquire_fair_semaphore(self.conn, &#39;testsem&#39;, 3, 1)
        self.assertTrue(r)
        print &quot;Got one!&quot;
        print &quot;Let&#39;s release it...&quot;
        self.assertTrue(release_fair_semaphore(self.conn, &#39;testsem&#39;, r))
        print &quot;Released!&quot;
        print
        print &quot;And let&#39;s make sure we can get 3 more!&quot;
        for i in xrange(3):
            self.assertTrue(acquire_fair_semaphore(self.conn, &#39;testsem&#39;, 3, 1))
        print &quot;We got them!&quot;
        self.conn.delete(&#39;testsem&#39;, &#39;testsem:owner&#39;, &#39;testsem:counter&#39;)

    def test_delayed_tasks(self):
        import threading
        self.conn.delete(&#39;queue:tqueue&#39;, &#39;delayed:&#39;)
        print &quot;Let&#39;s start some regular and delayed tasks...&quot;
        for delay in [0, .5, 0, 1.5]:
            self.assertTrue(execute_later(self.conn, &#39;tqueue&#39;, &#39;testfn&#39;, [], delay))
        r = self.conn.llen(&#39;queue:tqueue&#39;)
        print &quot;How many non-delayed tasks are there (should be 2)?&quot;, r
        self.assertEquals(r, 2)
        print
        print &quot;Let&#39;s start up a thread to bring those delayed tasks back...&quot;
        t = threading.Thread(target=poll_queue, args=(self.conn,))
        t.setDaemon(1)
        t.start()
        print &quot;Started.&quot;
        print &quot;Let&#39;s wait for those tasks to be prepared...&quot;
        time.sleep(2)
        global QUIT
        QUIT = True
        t.join()
        r = self.conn.llen(&#39;queue:tqueue&#39;)
        print &quot;Waiting is over, how many tasks do we have (should be 4)?&quot;, r
        self.assertEquals(r, 4)
        self.conn.delete(&#39;queue:tqueue&#39;, &#39;delayed:&#39;)

    def test_multi_recipient_messaging(self):
        self.conn.delete(&#39;ids:chat:&#39;, &#39;msgs:1&#39;, &#39;ids:1&#39;, &#39;seen:joe&#39;, &#39;seen:jeff&#39;, &#39;seen:jenny&#39;)

        print &quot;Let&#39;s create a new chat session with some recipients...&quot;
        chat_id = create_chat(self.conn, &#39;joe&#39;, [&#39;jeff&#39;, &#39;jenny&#39;], &#39;message 1&#39;)
        print &quot;Now let&#39;s send a few messages...&quot;
        for i in xrange(2, 5):
            send_message(self.conn, chat_id, &#39;joe&#39;, &#39;message %s&#39;%i)
        print
        print &quot;And let&#39;s get the messages that are waiting for jeff and jenny...&quot;
        r1 = fetch_pending_messages(self.conn, &#39;jeff&#39;)
        r2 = fetch_pending_messages(self.conn, &#39;jenny&#39;)
        print &quot;They are the same?&quot;, r1==r2
        self.assertEquals(r1, r2)
        print &quot;Those messages are:&quot;
        import pprint
        pprint.pprint(r1)
        self.conn.delete(&#39;ids:chat:&#39;, &#39;msgs:1&#39;, &#39;ids:1&#39;, &#39;seen:joe&#39;, &#39;seen:jeff&#39;, &#39;seen:jenny&#39;)

    def test_file_distribution(self):
        import gzip, shutil, tempfile, threading
        self.conn.delete(&#39;test:temp-1.txt&#39;, &#39;test:temp-2.txt&#39;, &#39;test:temp-3.txt&#39;, &#39;msgs:test:&#39;, &#39;seen:0&#39;, &#39;seen:source&#39;, &#39;ids:test:&#39;, &#39;chat:test:&#39;)

        dire = tempfile.mkdtemp()
        try:
            print &quot;Creating some temporary &#39;log&#39; files...&quot;
            with open(dire + &#39;/temp-1.txt&#39;, &#39;wb&#39;) as f:
                f.write(&#39;one line\n&#39;)
            with open(dire + &#39;/temp-2.txt&#39;, &#39;wb&#39;) as f:
                f.write(10000 * &#39;many lines\n&#39;)
            out = gzip.GzipFile(dire + &#39;/temp-3.txt.gz&#39;, mode=&#39;wb&#39;)
            for i in xrange(100000):
                out.write(&#39;random line %s\n&#39;%(os.urandom(16).encode(&#39;hex&#39;),))
            out.close()
            size = os.stat(dire + &#39;/temp-3.txt.gz&#39;).st_size
            print &quot;Done.&quot;
            print
            print &quot;Starting up a thread to copy logs to redis...&quot;
            t = threading.Thread(target=copy_logs_to_redis, args=(self.conn, dire, &#39;test:&#39;, 1, size))
            t.setDaemon(1)
            t.start()

            print &quot;Let&#39;s pause to let some logs get copied to Redis...&quot;
            time.sleep(.25)
            print
            print &quot;Okay, the logs should be ready. Let&#39;s process them!&quot;

            index = [0]
            counts = [0, 0, 0]
            def callback(conn, line):
                if line is None:
                    print &quot;Finished with a file %s, linecount: %s&quot;%(index[0], counts[index[0]])
                    index[0] += 1
                elif line or line.endswith(&#39;\n&#39;):
                    counts[index[0]] += 1

            print &quot;Files should have 1, 10000, and 100000 lines&quot;
            process_logs_from_redis(self.conn, &#39;0&#39;, callback)
            self.assertEquals(counts, [1, 10000, 100000])

            print
            print &quot;Let&#39;s wait for the copy thread to finish cleaning up...&quot;
            t.join()
            print &quot;Done cleaning out Redis!&quot;

        finally:
            print &quot;Time to clean up files...&quot;
            shutil.rmtree(dire)
            print &quot;Cleaned out files!&quot;
        self.conn.delete(&#39;test:temp-1.txt&#39;, &#39;test:temp-2.txt&#39;, &#39;test:temp-3.txt&#39;, &#39;msgs:test:&#39;, &#39;seen:0&#39;, &#39;seen:source&#39;, &#39;ids:test:&#39;, &#39;chat:test:&#39;)

if __name__ == &#39;__main__&#39;:
    unittest.main()
</pre></div>
</div>
</div>



            <div class="section" id="discuss">
    <h2>
        讨论
        <a class="headerlink" href="#discuss" title="永久链接至标题">¶</a>
    </h2>
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'redisinaction'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="chapter7.html" title="第 7 章相关源代码"
             >next</a> |</li>
        <li class="right" >
          <a href="chapter5.html" title="第 5 章相关源代码"
             >previous</a> |</li>
        <li><a href="../index.html">Redis 实战</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, 黄健宏（huangz）.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
    </div>
  </body>
</html>